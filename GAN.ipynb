{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, img_width, img_height, img_channels, DM_optimizer = RMSprop(lr = 0.0002, decay = 6e-8),\\\n",
    "                 AM_optimizer = RMSprop(lr = 0.0001, decay = 3e-8), print_summary = False):\n",
    "        \n",
    "        self.input_shape = (img_width, img_height, img_channels)\n",
    "        self.input_noice_dim = 100\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"Generator:\")\n",
    "        self.Gen = self.__generator(print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nDiscriminator:\")\n",
    "        self.Dis = self.__discriminator(print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nDM:\")\n",
    "        self.DM = self.__dm(DM_optimizer, print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nAM:\")\n",
    "        self.AM = self.__am(AM_optimizer, print_summary)\n",
    "        \n",
    "    def __generator(self, print_summary = False):\n",
    "        g = Sequential()\n",
    "        dropout = 0.5\n",
    "        depth = 256\n",
    "        dim = int(self.input_shape[0] / 4)\n",
    "        \n",
    "        g.add(Dense(dim * dim * depth, input_dim = self.input_noice_dim))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        g.add(Reshape((dim, dim, depth)))\n",
    "        g.add(Dropout(dropout))\n",
    "        \n",
    "        g.add(UpSampling2D())\n",
    "        g.add(Conv2DTranspose(int(depth / 2), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(UpSampling2D())\n",
    "        g.add(Conv2DTranspose(int(depth / 4), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(Conv2DTranspose(int(depth / 8), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(Conv2DTranspose(self.input_shape[2], 5, padding = 'same'))\n",
    "        g.add(Activation('tanh')) #tu by≈Ç sigmoid\n",
    "        \n",
    "        if print_summary:\n",
    "            g.summary()\n",
    "\n",
    "        return g\n",
    "    \n",
    "    def __discriminator(self, print_summary = False):\n",
    "        d = Sequential()\n",
    "        dropout = 0.5\n",
    "        depth = 64\n",
    "        \n",
    "        d.add(Conv2D(depth * 1, 5, strides = 2, input_shape = self.input_shape, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 2, 5, strides = 2, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 4, 5, strides = 2, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 8, 5, strides = 1, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Flatten())\n",
    "        d.add(Dense(1))\n",
    "        d.add(Activation('sigmoid'))\n",
    "        \n",
    "        if print_summary:\n",
    "            d.summary()\n",
    "            \n",
    "        return d\n",
    "    \n",
    "    def __dm(self, optimizer, print_summary = False):\n",
    "        self.Dis.trainable = True\n",
    "        dm = Sequential()\n",
    "        dm.add(self.Dis)\n",
    "        \n",
    "        if print_summary:\n",
    "            dm.summary()\n",
    "        \n",
    "        dm.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "        \n",
    "        return dm\n",
    "    \n",
    "    def __am(self, optimizer, print_summary = False):\n",
    "        #Freezing Discriminator weights during the generator adversarial training\n",
    "        self.Dis.trainable = False\n",
    "        am = Sequential()\n",
    "        am.add(self.Gen)\n",
    "        am.add(self.Dis)\n",
    "        \n",
    "        if print_summary:\n",
    "            am.summary()\n",
    "        \n",
    "        am.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "        \n",
    "        return am\n",
    "    \n",
    "    def train(self, steps, batch_size, dataset, info_rate = 10):\n",
    "        for i in range(steps):\n",
    "            r = dataset.get_random_batch(batch_size)\n",
    "            noise = np.random.uniform(-1.0, 1.0, size = [batch_size, self.input_noice_dim])\n",
    "            f = self.Gen.predict(noise)\n",
    "            x = np.concatenate((r, f))\n",
    "            y = np.ones([2 * batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            dm_loss = self.DM.train_on_batch(x, y)\n",
    "            \n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.input_noice_dim])\n",
    "            am_loss = self.AM.train_on_batch(noise, y)\n",
    "            \n",
    "            if i % info_rate == 0:\n",
    "                print(\"Step:\", i, \"DM loss:\", dm_loss, \"AM loss:\", am_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202599, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "celeba_dirs = glob(os.path.join('.', 'img_align_celeba', '*.jpg'))\n",
    "celeba_dataset = helper.ImagesDataset(celeba_dirs, 'RGB', helper.celeba_preprocessing, width=28, height=28)\n",
    "print(celeba_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 3)         0         \n",
      "=================================================================\n",
      "Total params: 2,395,843\n",
      "Trainable params: 2,370,307\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "\n",
      "Discriminator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "DM:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 1)                 4314753   \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "AM:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 3)         2395843   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 4314753   \n",
      "=================================================================\n",
      "Total params: 6,710,596\n",
      "Trainable params: 2,370,307\n",
      "Non-trainable params: 4,340,289\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00025\n",
    "beta1 = 0.45\n",
    "\n",
    "face_cnn = GAN(28, 28, 3, DM_optimizer = Adam(lr = learning_rate, beta_1 = beta1),\\\n",
    "               AM_optimizer = Adam(lr = learning_rate, beta_1 = beta1), print_summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wektor/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 DM loss: [0.6942121, 0.53125] AM loss: [0.5018597, 1.0]\n",
      "Step: 1000 DM loss: [0.49123043, 0.7734375] AM loss: [2.6708996, 0.0]\n",
      "Step: 2000 DM loss: [0.15907975, 0.9375] AM loss: [0.16056088, 0.9375]\n",
      "Step: 3000 DM loss: [0.03329023, 0.984375] AM loss: [0.0477017, 0.984375]\n",
      "Step: 4000 DM loss: [0.19000661, 0.921875] AM loss: [1.2831316, 0.265625]\n"
     ]
    }
   ],
   "source": [
    "face_cnn.train(30000, 64, celeba_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1.0, 1.0, size = [1, face_cnn.input_noice_dim])\n",
    "i = face_cnn.Gen.predict(noise)\n",
    "print(face_cnn.Dis.predict(i))\n",
    "#i = (((i - i.min()) * 255) / (i.max() - i.min())).astype(np.uint8)\n",
    "plt.imshow(helper.image_for_plot(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cnn.AM.save('face_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_upsampled = tf.keras.backend.resize_images(image_scaled.reshape([1, 28, 28, 3]), 4, 4, \"channels_last\")\n",
    "print(image_upsampled.shape)\n",
    "print(image_upsampled)\n",
    "plt.imshow(tf.to_float(image_upsampled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us = Upsampler(4)\n",
    "\n",
    "image_upsampled = us.upsample(image_scaled.reshape([1, 28, 28, 3]))\n",
    "print(image_upsampled.shape)\n",
    "plt.imshow(image_upsampled[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
