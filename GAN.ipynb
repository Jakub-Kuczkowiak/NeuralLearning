{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wektor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, img_width, img_height, img_channels, DM_optimizer = RMSprop(lr = 0.0002, decay = 6e-8),\\\n",
    "                 AM_optimizer = RMSprop(lr = 0.0001, decay = 3e-8), print_summary = False):\n",
    "        \n",
    "        self.input_shape = (img_width, img_height, img_channels)\n",
    "        self.input_noice_dim = 100\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"Generator:\")\n",
    "        self.Gen = self.__generator(print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nDiscriminator:\")\n",
    "        self.Dis = self.__discriminator(print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nDM:\")\n",
    "        self.DM = self.__dm(DM_optimizer, print_summary)\n",
    "        \n",
    "        if print_summary:\n",
    "            print(\"\\nAM:\")\n",
    "        self.AM = self.__am(AM_optimizer, print_summary)\n",
    "        \n",
    "    def __generator(self, print_summary = False):\n",
    "        g = Sequential()\n",
    "        dropout = 0.5\n",
    "        depth = 256\n",
    "        dim = int(self.input_shape[0] / 4)\n",
    "        \n",
    "        g.add(Dense(dim * dim * depth, input_dim = self.input_noice_dim))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        g.add(Reshape((dim, dim, depth)))\n",
    "        g.add(Dropout(dropout))\n",
    "        \n",
    "        g.add(UpSampling2D())\n",
    "        g.add(Conv2DTranspose(int(depth / 2), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(UpSampling2D())\n",
    "        g.add(Conv2DTranspose(int(depth / 4), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(Conv2DTranspose(int(depth / 8), 5, padding = 'same'))\n",
    "        g.add(BatchNormalization(momentum = 0.99))\n",
    "        g.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        g.add(Conv2DTranspose(self.input_shape[2], 5, padding = 'same'))\n",
    "        g.add(Activation('tanh')) #tu by≈Ç sigmoid\n",
    "        \n",
    "        if print_summary:\n",
    "            g.summary()\n",
    "\n",
    "        return g\n",
    "    \n",
    "    def __discriminator(self, print_summary = False):\n",
    "        d = Sequential()\n",
    "        dropout = 0.5\n",
    "        depth = 64\n",
    "        \n",
    "        d.add(Conv2D(depth * 1, 5, strides = 2, input_shape = self.input_shape, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 2, 5, strides = 2, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 4, 5, strides = 2, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Conv2D(depth * 8, 5, strides = 1, padding = 'same'))\n",
    "        d.add(LeakyReLU(alpha = 0.2))\n",
    "        d.add(Dropout(dropout))\n",
    "        \n",
    "        d.add(Flatten())\n",
    "        d.add(Dense(1))\n",
    "        d.add(Activation('sigmoid'))\n",
    "        \n",
    "        if print_summary:\n",
    "            d.summary()\n",
    "            \n",
    "        return d\n",
    "    \n",
    "    def __dm(self, optimizer, print_summary = False):\n",
    "        self.Dis.trainable = True\n",
    "        dm = Sequential()\n",
    "        dm.add(self.Dis)\n",
    "        \n",
    "        if print_summary:\n",
    "            dm.summary()\n",
    "        \n",
    "        dm.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "        \n",
    "        return dm\n",
    "    \n",
    "    def __am(self, optimizer, print_summary = False):\n",
    "        #Freezing Discriminator weights during the generator adversarial training\n",
    "        self.Dis.trainable = False\n",
    "        am = Sequential()\n",
    "        am.add(self.Gen)\n",
    "        am.add(self.Dis)\n",
    "        \n",
    "        if print_summary:\n",
    "            am.summary()\n",
    "        \n",
    "        am.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "        \n",
    "        return am\n",
    "    \n",
    "    def train(self, steps, batch_size, dataset, info_rate = 10):\n",
    "        for i in range(steps):\n",
    "            r = dataset.get_random_batch(batch_size)\n",
    "            noise = np.random.uniform(-1.0, 1.0, size = [batch_size, self.input_noice_dim])\n",
    "            f = self.Gen.predict(noise)\n",
    "            x = np.concatenate((r, f))\n",
    "            y = np.ones([2 * batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            dm_loss = self.DM.train_on_batch(x, y)\n",
    "            \n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.input_noice_dim])\n",
    "            am_loss = self.AM.train_on_batch(noise, y)\n",
    "            \n",
    "            if i % info_rate == 0:\n",
    "                print(\"Step:\", i, \"DM loss:\", dm_loss, \"AM loss:\", am_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202599, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "celeba_dirs = glob(os.path.join('.', 'img_align_celeba', '*.jpg'))\n",
    "celeba_dataset = helper.ImagesDataset(celeba_dirs, 'RGB', helper.celeba_preprocessing, width=28, height=28)\n",
    "print(celeba_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 3)         2403      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 3)         0         \n",
      "=================================================================\n",
      "Total params: 2,395,843\n",
      "Trainable params: 2,370,307\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "\n",
      "Discriminator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "DM:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 1)                 4314753   \n",
      "=================================================================\n",
      "Total params: 4,314,753\n",
      "Trainable params: 4,314,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "AM:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 3)         2395843   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 4314753   \n",
      "=================================================================\n",
      "Total params: 6,710,596\n",
      "Trainable params: 2,370,307\n",
      "Non-trainable params: 4,340,289\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00025\n",
    "beta1 = 0.45\n",
    "\n",
    "face_cnn = GAN(28, 28, 3, DM_optimizer = Adam(lr = learning_rate, beta_1 = beta1),\\\n",
    "               AM_optimizer = Adam(lr = learning_rate, beta_1 = beta1), print_summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wektor/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 DM loss: [0.6897504, 0.4375] AM loss: [0.43878853, 1.0]\n",
      "Step: 1000 DM loss: [0.460682, 0.7734375] AM loss: [0.54596114, 0.65625]\n",
      "Step: 2000 DM loss: [0.3592868, 0.8515625] AM loss: [0.24126184, 0.875]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-da74c138c54f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mface_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceleba_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-8f3816e6943f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps, batch_size, dataset, info_rate)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_noice_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mam_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minfo_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "face_cnn.train(30000, 64, celeba_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1.0, 1.0, size = [1, face_cnn.input_noice_dim])\n",
    "i = face_cnn.Gen.predict(noise)\n",
    "print(face_cnn.Dis.predict(i))\n",
    "i = (((i - i.min()) * 255) / (i.max() - i.min())).astype(np.uint8)\n",
    "plt.imshow(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cnn.AM.save('face_gen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_upsampled = tf.keras.backend.resize_images(image_scaled.reshape([1, 28, 28, 3]), 4, 4, \"channels_last\")\n",
    "print(image_upsampled.shape)\n",
    "print(image_upsampled)\n",
    "plt.imshow(tf.to_float(image_upsampled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us = Upsampler(4)\n",
    "\n",
    "image_upsampled = us.upsample(image_scaled.reshape([1, 28, 28, 3]))\n",
    "print(image_upsampled.shape)\n",
    "plt.imshow(image_upsampled[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
